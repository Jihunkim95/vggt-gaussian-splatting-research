# ğŸ—ºï¸ RL Frame Selector - ì—°êµ¬ ë¡œë“œë§µ

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-11-13
**í”„ë¡œì íŠ¸ ìƒíƒœ**: âœ… ì¸í”„ë¼ êµ¬ì¶• ì™„ë£Œ â†’ ğŸ”¬ ì‹¤í—˜ ë‹¨ê³„

---

## ğŸ“Š í˜„ì¬ ìƒíƒœ

### âœ… ì™„ë£Œ í•­ëª© (2025-11-12 ~ 2025-11-13)

1. **í•µì‹¬ ì¸í”„ë¼**
   - âœ… `phase1_surrogate/env.py`: Surrogate rewardë¥¼ ì‚¬ìš©í•˜ëŠ” Gymnasium í™˜ê²½
   - âœ… `phase1_surrogate/train.py`: Multi-video ì§€ì› PPO í•™ìŠµ
   - âœ… `utils/dataset_loader.py`: CO3Dv2/DTU/Custom ë°ì´í„°ì…‹ ë¡œë”
   - âœ… `utils/quality_metrics.py`: Sharpness, BRISQUE, brightness ë©”íŠ¸ë¦­
   - âœ… `utils/overlap_utils.py`: SIFT ê¸°ë°˜ overlap ê³„ì‚°

2. **ë¬¸ì„œí™”**
   - âœ… `RL_PROJECT_PROPOSAL.md`: CO3Dv2 ë§ˆì´ê·¸ë ˆì´ì…˜ í¬í•¨ í•™ìˆ  ì œì•ˆì„œ
   - âœ… `QUICKSTART.md`: 5ë¶„ ì‹œì‘ ê°€ì´ë“œ
   - âœ… `OVERLAP_FIX.md`: Overlap constraint êµ¬í˜„ ì„¤ëª…
   - âœ… `CO3D_MIGRATION.md`: Zero-shot generalization ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ

3. **ì£¼ìš” ê¸°ëŠ¥**
   - âœ… Multi-video í•™ìŠµ (episodeë§ˆë‹¤ ëœë¤ ë¹„ë””ì˜¤ ì„ íƒ)
   - âœ… ë³‘ë ¬ í™˜ê²½ (SubprocVecEnv, 4-8ê°œ í™˜ê²½)
   - âœ… Overlap constraint (COLMAP í˜¸í™˜ì„ ìœ„í•œ max_gap=10)
   - âœ… Surrogate reward (temporal uniformity + quality + diversity + overlap)

---

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

### Priority 1: ì¦‰ì‹œ ì‹¤í–‰ (ì˜¤ëŠ˜/ì´ë²ˆ ì£¼)

#### 1.1 DTU Quick Test (30ë¶„) ì™„ë£Œ

**ëª©í‘œ**: End-to-end êµ¬í˜„ ê²€ì¦

**ì‹¤í–‰ ì»¤ë§¨ë“œ**:
```bash
cd /data/vggt-gaussian-splatting-research/rl_frame_selector/phase1_surrogate

# í™˜ê²½ í™œì„±í™”
source ../../env/vggt_env/bin/activate

# DTU ìŠ¤ìº”ìœ¼ë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
python train.py \
    --dataset dtu \
    --num-train-videos 3 \
    --num-eval-videos 1 \
    --total-timesteps 10000 \
    --n-envs 2 \
    --output-dir ./trained_models/dtu_quicktest \
    --tensorboard-log ./logs/dtu_quicktest
```

**ì˜ˆìƒ ê²°ê³¼**:
- ì—ëŸ¬ ì—†ì´ í•™ìŠµ ì™„ë£Œ
- ìµœì¢… ëª¨ë¸ ì €ì¥: `./trained_models/dtu_quicktest/final_model.zip`
- Tensorboard ë¡œê·¸ ìƒì„±
- Episode rewardê°€ 10k timesteps ë™ì•ˆ ~0.3 â†’ ~0.5+ ì¦ê°€

**ì„±ê³µ ê¸°ì¤€**:
- âœ… ë°ì´í„°ì…‹ ë¡œë”© ì—ëŸ¬ ì—†ìŒ
- âœ… í™˜ê²½ ë¦¬ì…‹ ì„±ê³µ
- âœ… PPO agentê°€ í¬ë˜ì‹œ ì—†ì´ í•™ìŠµ
- âœ… Rewardê°€ ìƒìŠ¹ ì¶”ì„¸

---

#### 1.2 `evaluate.py` ìƒì„± (í•„ìˆ˜)

**ëª©í‘œ**: í•™ìŠµëœ ëª¨ë¸ì„ ìƒˆ ë¹„ë””ì˜¤ì—ì„œ í…ŒìŠ¤íŠ¸ (zero-shot evaluation)

**íŒŒì¼**: `./rl_frame_selector/evaluate.py`

**êµ¬í˜„**:
```python
#!/usr/bin/env python3
"""
Zero-shot í‰ê°€ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python evaluate.py \
        --model ./trained_models/final_model.zip \
        --video /path/to/new/video.mp4 \
        --output-dir ./eval_results/video1
"""
import argparse
import json
import sys
sys.path.append('./phase1_surrogate')

from pathlib import Path
from stable_baselines3 import PPO
from env import FrameSelectionEnv


def evaluate_video(
    model_path: str,
    video_path: str,
    num_source_frames: int = 300,
    target_frames: int = 60,
    max_gap: int = 10,
    output_dir: str = None
):
    """
    ë‹¨ì¼ ë¹„ë””ì˜¤ì— ëŒ€í•œ Zero-shot í‰ê°€

    ë°˜í™˜ê°’:
        dict: {
            'selected_frames': [0, 5, 10, ...],
            'final_reward': 0.75,
            'temporal_uniformity': 0.8,
            'avg_quality': 0.75,
            'diversity': 0.6,
            'overlap_score': 0.85,
            'num_frames': 60
        }
    """
    print(f"ğŸ“¹ ë¹„ë””ì˜¤ ë¡œë”©: {video_path}")

    # í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ
    model = PPO.load(model_path)
    print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")

    # í™˜ê²½ ìƒì„±
    env = FrameSelectionEnv(
        video_path=video_path,
        num_source_frames=num_source_frames,
        target_frames=target_frames,
        max_gap=max_gap
    )

    # Episode ì‹¤í–‰
    obs, _ = env.reset()
    selected_frames = []

    print(f"ğŸ¯ {num_source_frames}ê°œ ì¤‘ {target_frames}ê°œ í”„ë ˆì„ ì„ íƒ ì¤‘...")

    for step in range(num_source_frames):
        action, _ = model.predict(obs, deterministic=True)
        obs, reward, done, truncated, info = env.step(action)

        if action == 1:
            selected_frames.append(info['current_step'] - 1)

        if done or truncated:
            break

    # Infoì—ì„œ ìµœì¢… ë©”íŠ¸ë¦­ ì¶”ì¶œ
    results = {
        'video_path': video_path,
        'model_path': model_path,
        'selected_frames': selected_frames,
        'num_frames': len(selected_frames),
        'final_reward': float(reward),
        'temporal_uniformity': float(info.get('temporal_uniformity', 0)),
        'avg_quality': float(info.get('avg_quality', 0)),
        'diversity': float(info.get('diversity', 0)),
        'overlap_score': float(info.get('overlap_score', 0))
    }

    print("\n" + "="*70)
    print("ğŸ“Š í‰ê°€ ê²°ê³¼")
    print("="*70)
    print(f"ì„ íƒëœ í”„ë ˆì„: {len(selected_frames)}/{target_frames}")
    print(f"ìµœì¢… Reward: {results['final_reward']:.4f}")
    print(f"  - Temporal Uniformity: {results['temporal_uniformity']:.4f}")
    print(f"  - í‰ê·  Quality: {results['avg_quality']:.4f}")
    print(f"  - Diversity: {results['diversity']:.4f}")
    print(f"  - Overlap Score: {results['overlap_score']:.4f}")
    print("="*70)

    # ê²°ê³¼ ì €ì¥
    if output_dir:
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        results_file = output_path / "evaluation_results.json"
        with open(results_file, 'w') as f:
            json.dump(results, f, indent=2)

        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {results_file}")

        # ì„ íƒëœ í”„ë ˆì„ ì¸ë±ìŠ¤ ì €ì¥
        frames_file = output_path / "selected_frames.txt"
        with open(frames_file, 'w') as f:
            f.write('\n'.join(map(str, selected_frames)))

        print(f"ğŸ’¾ í”„ë ˆì„ ì¸ë±ìŠ¤ ì €ì¥: {frames_file}")

    return results


def main():
    parser = argparse.ArgumentParser(description='Zero-shot í‰ê°€')

    parser.add_argument('--model', type=str, required=True,
                       help='í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ (.zip)')
    parser.add_argument('--video', type=str, required=True,
                       help='ë¹„ë””ì˜¤ íŒŒì¼ ë˜ëŠ” ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ ê²½ë¡œ')
    parser.add_argument('--num-source-frames', type=int, default=300,
                       help='ë¹„ë””ì˜¤ì—ì„œ ì¶”ì¶œí•  í”„ë ˆì„ ìˆ˜')
    parser.add_argument('--target-frames', type=int, default=60,
                       help='ì„ íƒí•  í”„ë ˆì„ ìˆ˜')
    parser.add_argument('--max-gap', type=int, default=10,
                       help='ì—°ì† ì„ íƒ í”„ë ˆì„ ê°„ ìµœëŒ€ gap')
    parser.add_argument('--output-dir', type=str, default=None,
                       help='ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ (ì„ íƒ)')

    args = parser.parse_args()

    evaluate_video(
        model_path=args.model,
        video_path=args.video,
        num_source_frames=args.num_source_frames,
        target_frames=args.target_frames,
        max_gap=args.max_gap,
        output_dir=args.output_dir
    )


if __name__ == '__main__':
    main()
```

**ì‚¬ìš© ì˜ˆì‹œ**:
```bash
# ìƒˆ DTU ìŠ¤ìº”ì—ì„œ í…ŒìŠ¤íŠ¸
python evaluate.py \
    --model ./trained_models/dtu_quicktest/final_model.zip \
    --video ../datasets/DTU/scan37_standard \
    --output-dir ./eval_results/scan37

# ì»¤ìŠ¤í…€ ë¹„ë””ì˜¤ì—ì„œ í…ŒìŠ¤íŠ¸
python evaluate.py \
    --model ./trained_models/dtu_quicktest/final_model.zip \
    --video ../datasets/custom/cLectern.mp4 \
    --output-dir ./eval_results/cLectern
```

---

### Priority 2: ë…¼ë¬¸ìš© í•„ìˆ˜ (ì´ë²ˆ ì£¼/ë‹¤ìŒ ì£¼)

#### 2.1 `baselines.py` ìƒì„±

**ëª©í‘œ**: ë¹„êµë¥¼ ìœ„í•œ baseline ë°©ë²• êµ¬í˜„

**íŒŒì¼**: `./rl_frame_selector/baselines.py`

**êµ¬í˜„í•  ë°©ë²•ë“¤**:

1. **Random Baseline**
   ```python
   def random_selection(frames, target_frames, seed=42):
       """ëœë¤í•˜ê²Œ target_framesê°œ ì„ íƒ"""
       np.random.seed(seed)
       return sorted(np.random.choice(len(frames), target_frames, replace=False))
   ```

2. **Uniform Baseline**
   ```python
   def uniform_selection(frames, target_frames):
       """ê· ë“± ê°„ê²©ìœ¼ë¡œ í”„ë ˆì„ ì„ íƒ"""
       step = len(frames) / target_frames
       return [int(i * step) for i in range(target_frames)]
   ```

3. **Quality-based Baseline**
   ```python
   def quality_selection(frames, target_frames):
       """ìƒìœ„ í’ˆì§ˆ í”„ë ˆì„ ì„ íƒ (sharpness ê¸°ì¤€)"""
       qualities = [compute_sharpness(f) for f in frames]
       top_indices = np.argsort(qualities)[-target_frames:]
       return sorted(top_indices)
   ```

4. **Stratified Baseline** (í˜„ì¬ ìµœê³  heuristic)
   ```python
   def stratified_selection(frames, target_frames, num_segments=10):
       """
       êµ¬ê°„ë³„ë¡œ ë‚˜ëˆ„ê³  ê° êµ¬ê°„ì—ì„œ ìµœê³  í’ˆì§ˆ í”„ë ˆì„ ì„ íƒ
       (ì›ë˜ íŒŒì´í”„ë¼ì¸ì—ì„œ ì‚¬ìš©í•˜ëŠ” baseline)
       """
       segment_size = len(frames) // num_segments
       selected = []

       for i in range(num_segments):
           start = i * segment_size
           end = start + segment_size
           segment = frames[start:end]

           # êµ¬ê°„ ë‚´ ìµœê³  í’ˆì§ˆ í”„ë ˆì„ ì„ íƒ
           qualities = [compute_sharpness(f) for f in segment]
           best_idx = start + np.argmax(qualities)
           selected.append(best_idx)

       return sorted(selected[:target_frames])
   ```

**ë¹„êµ ìŠ¤í¬ë¦½íŠ¸**:
```python
def compare_baselines(video_path, output_dir):
    """
    ë‹¨ì¼ ë¹„ë””ì˜¤ì—ì„œ ëª¨ë“  baseline ë¹„êµ

    ì¶œë ¥:
        - ë¹„êµ í‘œ (markdown)
        - ë©”íŠ¸ë¦­ JSON
        - ì„ íƒëœ í”„ë ˆì„ ì‹œê°í™”
    """
    methods = {
        'Random': random_selection,
        'Uniform': uniform_selection,
        'Quality': quality_selection,
        'Stratified': stratified_selection
    }

    results = {}
    for name, method in methods.items():
        selected = method(frames, target_frames=60)
        reward = compute_surrogate_reward(frames, selected)
        results[name] = {
            'reward': reward,
            'selected_frames': selected
        }

    # ë¹„êµ í‘œ ìƒì„±
    print_comparison_table(results)

    # ê²°ê³¼ ì €ì¥
    save_results(results, output_dir)
```

**ì˜ˆìƒ Baseline ì„±ëŠ¥** (CO3D_MIGRATION.md ê¸°ì¤€):
```
| ë°©ë²•          | Temporal | Quality | Diversity | Reward |
|--------------|----------|---------|-----------|--------|
| Random       | 0.3      | 0.5     | 0.6       | 0.45   |
| Uniform      | 0.9      | 0.4     | 0.3       | 0.52   |
| Quality-only | 0.2      | 0.9     | 0.4       | 0.50   |
| Stratified   | 0.7      | 0.7     | 0.5       | 0.63   |
| RL Agent     | 0.8      | 0.8     | 0.6       | 0.73   |  â† ëª©í‘œ
```

---

#### 2.2 ë³¸ê²© DTU í•™ìŠµ (1-2ì‹œê°„)

**ëª©í‘œ**: ë” ë§ì€ DTU ìŠ¤ìº”ìœ¼ë¡œ í•™ìŠµí•˜ì—¬ ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ

**ì‹¤í–‰ ì»¤ë§¨ë“œ**:
```bash
cd /data/vggt-gaussian-splatting-research/rl_frame_selector/phase1_surrogate

python train.py \
    --dataset dtu \
    --num-train-videos 10 \
    --num-eval-videos 2 \
    --total-timesteps 100000 \
    --n-envs 4 \
    --output-dir ./trained_models/dtu_10scans \
    --tensorboard-log ./logs/dtu_10scans
```

**ì„±ê³µ ê¸°ì¤€**:
- Episode rewardê°€ 0.7+ ìˆ˜ë ´
- í‰ê°€ ì„¸íŠ¸ì—ì„œ ëª¨ë“  baseline ì„±ëŠ¥ ì´ˆê³¼
- ë¯¸í•™ìŠµ DTU ìŠ¤ìº”ì—ì„œ zero-shot ì„±ëŠ¥ í™•ì¸

---

#### 2.3 ì‹¤í—˜ ë³´ê³ ì„œ ì‘ì„±

**íŒŒì¼**: `./rl_frame_selector/EXPERIMENT_RESULTS.md`

**ë‚´ìš© êµ¬ì¡°**:
```markdown
# ì‹¤í—˜ ê²°ê³¼

## ì„¤ì •
- ë°ì´í„°ì…‹: DTU (í•™ìŠµ 10ê°œ ìŠ¤ìº”, í‰ê°€ 2ê°œ ìŠ¤ìº”)
- í•™ìŠµ: 100k timesteps, 4ê°œ ë³‘ë ¬ í™˜ê²½
- í‰ê°€: ë¯¸í•™ìŠµ ìŠ¤ìº”ì—ì„œ Zero-shot

## ê²°ê³¼

### í‘œ 1: Baseline ë¹„êµ (DTU scan37)
| ë°©ë²•       | Reward | Temporal | Quality | Diversity | Overlap |
|-----------|--------|----------|---------|-----------|---------|
| Random    | 0.45   | 0.30     | 0.50    | 0.60      | 0.40    |
| Uniform   | 0.52   | 0.90     | 0.40    | 0.30      | 0.85    |
| Quality   | 0.50   | 0.20     | 0.90    | 0.40      | 0.30    |
| Stratified| 0.63   | 0.70     | 0.70    | 0.50      | 0.70    |
| **RL Agent** | **0.73** | **0.80** | **0.80** | **0.60** | **0.85** |

### ê·¸ë¦¼ 1: í•™ìŠµ ê³¡ì„ 
[Reward ìˆ˜ë ´ì„ ë³´ì—¬ì£¼ëŠ” Tensorboard ìŠ¤í¬ë¦°ìƒ·]

### í‘œ 2: Zero-shot ì¼ë°˜í™”
| í…ŒìŠ¤íŠ¸ ë¹„ë””ì˜¤ | RL Agent | ìµœê³  Baseline | ê°œì„ ìœ¨ |
|-------------|----------|--------------|--------|
| scan37      | 0.73     | 0.63         | +15.9% |
| scan40      | 0.71     | 0.61         | +16.4% |
| cLectern    | 0.69     | 0.58         | +19.0% |

## ë…¼ì˜
- RL agentê°€ ë‹¤ëª©ì  ìµœì í™”ë¥¼ ì„±ê³µì ìœ¼ë¡œ í•™ìŠµ
- ëª¨ë“  íœ´ë¦¬ìŠ¤í‹± baseline ì„±ëŠ¥ ì´ˆê³¼
- Zero-shot ì¼ë°˜í™” ë‹¬ì„±
```

---

### Priority 3: ì„ íƒ ì‚¬í•­ / í–¥í›„ ì‘ì—…

#### 3.1 Phase 2 êµ¬í˜„

**ëª©í‘œ**: ì‹¤ì œ 3DGS ë©”íŠ¸ë¦­(PSNR/SSIM/LPIPS)ìœ¼ë¡œ fine-tuning

**íŒŒì¼**: `./rl_frame_selector/phase2_finetune/finetune.py` (ì´ë¯¸ ì¡´ì¬)

**í˜„ì¬ ìƒíƒœ**: ê³¨ê²© êµ¬í˜„ ì¡´ì¬, í†µí•© í•„ìš”

**êµ¬í˜„ ë‹¨ê³„**:
1. `finetune.py`ë¥¼ Phase 1 ëª¨ë¸ì„ ì´ˆê¸°í™”ë¡œ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •
2. `run_3dgs_pipeline()` í†µí•© êµ¬í˜„:
   ```python
   def run_3dgs_pipeline(selected_frames, dataset_dir):
       """
       ì‹¤ì œ 3DGS íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë° ë©”íŠ¸ë¦­ ë°˜í™˜

       ë‹¨ê³„:
           1. ì„ íƒëœ í”„ë ˆì„ì„ ì„ì‹œ ë””ë ‰í† ë¦¬ì— ë³µì‚¬
           2. VGGT/COLMAP reconstruction ì‹¤í–‰
           3. gsplat 1000 stepsë¡œ ë¹ ë¥´ê²Œ í•™ìŠµ
           4. PSNR/SSIM/LPIPS ë°˜í™˜

       ë°˜í™˜ê°’:
           dict: {'psnr': 19.5, 'ssim': 0.73, 'lpips': 0.21}
       """
       # run_pipeline.sh ì‚¬ìš© ë˜ëŠ” íŒŒì´í”„ë¼ì¸ ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ í˜¸ì¶œ
       pass
   ```

3. Reward í•¨ìˆ˜ ì—…ë°ì´íŠ¸:
   ```python
   # Phase 1: Surrogate reward (ë¹ ë¦„)
   reward_phase1 = 0.2*temporal + 0.3*quality + 0.1*diversity + 0.4*overlap

   # Phase 2: ì‹¤ì œ 3DGS ë©”íŠ¸ë¦­ (ëŠë¦¬ì§€ë§Œ ì •í™•)
   metrics = run_3dgs_pipeline(selected_frames, dataset_dir)
   reward_phase2 = metrics['psnr'] / 30.0  # [0, 1]ë¡œ ì •ê·œí™”
   ```

4. Fine-tuning ì „ëµ:
   ```bash
   # Phase 1 ëª¨ë¸ ë¡œë“œ ë° ì‹¤ì œ ë©”íŠ¸ë¦­ìœ¼ë¡œ fine-tune
   python finetune.py \
       --pretrained-model ../phase1_surrogate/trained_models/dtu_10scans/final_model.zip \
       --dataset dtu \
       --num-videos 5 \
       --total-timesteps 10000 \
       --pipeline P4  # ë¹ ë¥¸ íŒŒì´í”„ë¼ì¸ ì‚¬ìš©
   ```

**ì˜ˆìƒ ê²°ê³¼**:
- Phase 1 reward: 0.73 (surrogate)
- Phase 2 fine-tuning í›„: PSNR 19â†’20, SSIM 0.73â†’0.75

**ì°¸ê³ **: Phase 2ëŠ” ê³„ì‚° ë¹„ìš©ì´ ë†’ìŒ (~10ë¶„/episode). Phase 1 ê²°ê³¼ê°€ ìœ ë§í•  ë•Œë§Œ ì§„í–‰.

---

#### 3.2 CO3Dv2 ë³¸ê²© í•™ìŠµ

**ëª©í‘œ**: 1000+ ë¹„ë””ì˜¤ë¡œ í•™ìŠµí•˜ì—¬ ì§„ì •í•œ zero-shot ì¼ë°˜í™” ë‹¬ì„±

**ì‚¬ì „ ì¤€ë¹„**:
1. CO3Dv2 ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ (100+ GB)
   ```bash
   # ì§€ì¹¨ ì°¸ê³ : https://github.com/facebookresearch/co3d
   # /data/co3d/ ì— ì••ì¶• í•´ì œ
   ```

2. ë°ì´í„°ì…‹ êµ¬ì¡° í™•ì¸:
   ```bash
   ls /data/co3d/
   # ê²°ê³¼: apple/ backpack/ ball/ banana/ ... (50ê°œ ì¹´í…Œê³ ë¦¬)

   ls /data/co3d/apple/
   # ê²°ê³¼: 110_13051_23361/ ... (ë‹¤ìˆ˜ì˜ ì‹œí€€ìŠ¤)
   ```

**í•™ìŠµ ì»¤ë§¨ë“œ**:
```bash
cd /data/vggt-gaussian-splatting-research/rl_frame_selector/phase1_surrogate

python train.py \
    --dataset co3d \
    --num-train-videos 1000 \
    --num-eval-videos 100 \
    --total-timesteps 500000 \
    --n-envs 8 \
    --output-dir ./trained_models/co3d_1k \
    --tensorboard-log ./logs/co3d_1k
```

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: H100 GPUì—ì„œ 1-2ì‹œê°„

**ì˜ˆìƒ ê²°ê³¼**:
- ëª¨ë“  ë¹„ë””ì˜¤(DTU, CO3D, custom)ì—ì„œ zero-shot ì„±ëŠ¥
- ë‹¤ì–‘í•œ ë¬¼ì²´ ì¹´í…Œê³ ë¦¬, ì¡°ëª…, ì‹œì ì— ê±¸ì³ ì¼ë°˜í™”
- WACV 2026 ì œì¶œ ì¤€ë¹„ ì™„ë£Œ

**ì„±ê³µ ê¸°ì¤€**:
- âœ… 50ê°œ ì¹´í…Œê³ ë¦¬ì—ì„œ 1000+ ë¹„ë””ì˜¤ë¡œ í•™ìŠµ
- âœ… ë¯¸í•™ìŠµ ì¹´í…Œê³ ë¦¬ì—ì„œ zero-shot í‰ê°€
- âœ… ë‹¤ì–‘í•œ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ baseline ì´ˆê³¼ ì„±ëŠ¥
- âœ… ê³µê°œ ë°ì´í„°ì…‹ ì‚¬ìš©ìœ¼ë¡œ ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼

---

## ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìš”ì•½

### ì¦‰ì‹œ ì‹¤í–‰ (ì˜¤ëŠ˜)
- [ ] DTU quick test ì‹¤í–‰ (10k timesteps, 3ê°œ ìŠ¤ìº”)
- [ ] `evaluate.py` ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
- [ ] ë¯¸í•™ìŠµ DTU ìŠ¤ìº”ì—ì„œ zero-shot í‰ê°€ í…ŒìŠ¤íŠ¸

### ì´ë²ˆ ì£¼
- [ ] 4ê°€ì§€ baseline ë°©ë²•ìœ¼ë¡œ `baselines.py` ìƒì„±
- [ ] ë³¸ê²© DTU í•™ìŠµ ì‹¤í–‰ (100k timesteps, 10ê°œ ìŠ¤ìº”)
- [ ] RL agent vs baselines ë¹„êµ
- [ ] `EXPERIMENT_RESULTS.md` ìƒì„±

### ì„ íƒ ì‚¬í•­ / í–¥í›„
- [ ] Phase 2 fine-tuning êµ¬í˜„ (ì‹¤ì œ 3DGS ë©”íŠ¸ë¦­)
- [ ] CO3Dv2 ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
- [ ] CO3Dv2ë¡œ í•™ìŠµ (1000ê°œ ë¹„ë””ì˜¤)
- [ ] WACV 2026 ì œì¶œ

---

## ğŸ“ í•™ìˆ  ë§ˆì¼ìŠ¤í†¤

### ìµœì†Œ ë…¼ë¬¸ ìš”êµ¬ì‚¬í•­
- âœ… ìƒˆë¡œìš´ ë¬¸ì œ: RL ê¸°ë°˜ ì ì‘í˜• í”„ë ˆì„ ì„ íƒ
- âœ… ê¸°ìˆ ì  ê¸°ì—¬: Overlap-aware MDP ê³µì‹í™”
- â³ ì‹¤í—˜ ê²€ì¦: RL agent > baselines
- â³ Zero-shot ì¼ë°˜í™”: DTU í•™ìŠµ â†’ custom ë¹„ë””ì˜¤ í…ŒìŠ¤íŠ¸

### ê°•ë ¥í•œ ë…¼ë¬¸ (WACV 2026 ëª©í‘œ)
ìœ„ ìš”êµ¬ì‚¬í•­ + ì¶”ê°€:
- â³ ëŒ€ê·œëª¨ í•™ìŠµ: CO3Dv2 (1000+ ë¹„ë””ì˜¤)
- â³ Phase 2 ê²°ê³¼: ì‹¤ì œ 3DGS ë©”íŠ¸ë¦­
- â³ Ablation ì—°êµ¬: Overlap constraint, reward êµ¬ì„± ìš”ì†Œ
- â³ ì¬í˜„ì„±: ê³µê°œ ë°ì´í„°ì…‹, ì˜¤í”ˆì†ŒìŠ¤ ì½”ë“œ

---

## ğŸ“š ì£¼ìš” ì°¸ê³  ìë£Œ

1. **RL_PROJECT_PROPOSAL.md**: ì „ì²´ ë°©ë²•ë¡  í¬í•¨ í•™ìˆ  ì œì•ˆì„œ
2. **CO3D_MIGRATION.md**: Zero-shot ì¼ë°˜í™” ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ
3. **QUICKSTART.md**: 5ë¶„ ì‹œì‘ ê°€ì´ë“œ
4. **OVERLAP_FIX.md**: Overlap constraint êµ¬í˜„ ì„¸ë¶€ì‚¬í•­
5. **../docs/workflows/20251112_VGGT-GSplat_WorkFlow.md**: êµ¬í˜„ ê³¼ì • ë¬¸ì„œ

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘ (ë³µì‚¬-ë¶™ì—¬ë„£ê¸° ì»¤ë§¨ë“œ)

```bash
# 1. DTU Quick Test (30ë¶„)
cd /data/vggt-gaussian-splatting-research/rl_frame_selector/phase1_surrogate
source ../../env/vggt_env/bin/activate

python train.py \
    --dataset dtu \
    --num-train-videos 3 \
    --num-eval-videos 1 \
    --total-timesteps 10000 \
    --n-envs 2 \
    --output-dir ./trained_models/dtu_quicktest \
    --tensorboard-log ./logs/dtu_quicktest

# 2. í•™ìŠµ ëª¨ë‹ˆí„°ë§ (ìƒˆ í„°ë¯¸ë„)
tensorboard --logdir ./logs/dtu_quicktest --port 6006

# 3. evaluate.py ìƒì„± (TODO: ë¨¼ì € êµ¬í˜„)
# python ../evaluate.py \
#     --model ./trained_models/dtu_quicktest/final_model.zip \
#     --video ../../datasets/DTU/scan37_standard \
#     --output-dir ./eval_results/scan37

# 4. ë³¸ê²© í•™ìŠµ (1-2ì‹œê°„)
python train.py \
    --dataset dtu \
    --num-train-videos 10 \
    --num-eval-videos 2 \
    --total-timesteps 100000 \
    --n-envs 4 \
    --output-dir ./trained_models/dtu_10scans \
    --tensorboard-log ./logs/dtu_10scans
```

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-11-13
**ë‹¤ìŒ ë¦¬ë·°**: DTU quick test ì™„ë£Œ í›„
