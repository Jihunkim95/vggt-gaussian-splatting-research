# ğŸ”„ CO3Dv2 Multi-Video Trainingìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ

**Zero-shot Generalization ë‹¬ì„±!**

---

## ë³€ê²½ ì‚¬í•­ ìš”ì•½

### ë¬¸ì œì 
- ê¸°ì¡´: íŠ¹ì • ë¹„ë””ì˜¤ì— ëŒ€í•´ í•™ìŠµ â†’ ìƒˆ ë¹„ë””ì˜¤ë§ˆë‹¤ ì¬í•™ìŠµ í•„ìš”
- í•œê³„: ì‹¤ìš©ì„± ë¶€ì¡±, í™•ì¥ì„± ì—†ìŒ

### í•´ê²°ì±…
- CO3Dv2 ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ (1,000+ ë¹„ë””ì˜¤) í•™ìŠµ
- Zero-shot: í•™ìŠµ í›„ ìƒˆ ë¹„ë””ì˜¤ì— ì¦‰ì‹œ ì ìš© ê°€ëŠ¥
- ì¬í˜„ì„±: í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ ì‚¬ìš©

---

## ìˆ˜ì •ëœ íŒŒì¼

### 1. `RL_PROJECT_PROPOSAL.md` âœ…

**ì¶”ê°€ëœ ë‚´ìš©**:
- Section 3.2: ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ í•™ìŠµ (CO3Dv2)
- CO3Dv2 ì„ íƒ ì´ìœ  (í‘œì¤€í™”, ë‹¤ì–‘ì„±, 3D reconstruction ìµœì í™”)
- Zero-shot generalization ê°•ì¡°
- Reference [5] ì¶”ê°€: CO3Dv2 ë…¼ë¬¸ (Reizenstein et al., ICCV 2021)

**ì£¼ìš” ë³€ê²½**:
```markdown
### 3.2 ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ í•™ìŠµ (Generalization)

**í•™ìŠµ ë°ì´í„°ì…‹: CO3Dv2 (Common Objects in 3D v2)**
- í•™ìŠµ: 1,000ê°œ ë¹„ë””ì˜¤ (ë‹¤ì–‘í•œ ì‹œì , ì¡°ëª…, ì¥ë©´)
- í‰ê°€: DTU (ì •ì  ì¥ë©´) + Custom ë¹„ë””ì˜¤ (ë™ì  ì¥ë©´)
- **Zero-shot ì ìš©**: ìƒˆ ë¹„ë””ì˜¤ì— ì¬í•™ìŠµ ì—†ì´ ì¦‰ì‹œ ì ìš© ê°€ëŠ¥
```

---

### 2. `utils/dataset_loader.py` (NEW) âœ…

**ìƒˆë¡œ ìƒì„±ëœ íŒŒì¼**: ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ ë¡œë”© ì§€ì›

**ì£¼ìš” ê¸°ëŠ¥**:
```python
def load_co3d_videos(root, categories, num_videos, split, seed):
    """CO3Dv2 ë°ì´í„°ì…‹ì—ì„œ ë¹„ë””ì˜¤ ë¡œë“œ"""

def load_dtu_videos(root, scans):
    """DTU ìŠ¤ìº” ë””ë ‰í† ë¦¬ ë¡œë“œ"""

def load_custom_videos(root):
    """ì‚¬ìš©ì ë¹„ë””ì˜¤ ë¡œë“œ (.mp4, ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬)"""

def load_dataset(dataset_name, num_videos, **kwargs):
    """í†µí•© ë¡œë”: 'co3d', 'dtu', 'custom' ì§€ì›"""

def create_train_val_split(videos, val_ratio, seed):
    """Train/Val ë¶„ë¦¬"""
```

**ì˜ˆì‹œ**:
```python
# CO3Dv2 1000ê°œ ë¹„ë””ì˜¤ ë¡œë“œ
videos = load_dataset('co3d', num_videos=1000)

# DTU íŠ¹ì • ìŠ¤ìº” ë¡œë“œ
videos = load_dataset('dtu', scans=[1, 14, 24])

# ì‚¬ìš©ì ë¹„ë””ì˜¤ ë¡œë“œ
videos = load_dataset('custom', root='./my_videos')
```

---

### 3. `phase1_surrogate/train.py` âœ…

**ëŒ€ê·œëª¨ Multi-Video Training ì§€ì›**

**ë³€ê²½ëœ ì¸ì**:
```bash
# BEFORE (ë‹¨ì¼/ì†Œìˆ˜ ë¹„ë””ì˜¤)
--videos video1.mp4 video2.mp4

# AFTER (ë°ì´í„°ì…‹ ê¸°ë°˜)
--dataset co3d \
--num-train-videos 1000 \
--num-eval-videos 100 \
--n-envs 8
```

**ì£¼ìš” ë³€ê²½**:
1. **ë°ì´í„°ì…‹ ë¡œë”©**:
   - `load_dataset()` ì‚¬ìš©
   - Train/Val ìë™ ë¶„ë¦¬
   - 1,000+ ë¹„ë””ì˜¤ ì§€ì›

2. **ë³‘ë ¬ í™˜ê²½**:
   - `SubprocVecEnv` ì‚¬ìš© (8ê°œ ë³‘ë ¬ í™˜ê²½)
   - ê° episodeë§ˆë‹¤ ëœë¤ ë¹„ë””ì˜¤ ì„ íƒ
   - Multi-video generalization í•™ìŠµ

3. **í•™ìŠµ ê·œëª¨ ì¦ê°€**:
   - Total timesteps: 100k â†’ 500k
   - Parallel envs: 1 â†’ 4-8

**ì½”ë“œ ì˜ˆì‹œ**:
```python
def make_env(video_list, rank, seed=0):
    def _init():
        video_path = random.choice(video_list)  # ëœë¤ ì„ íƒ
        env = FrameSelectionEnv(video_path, ...)
        return env
    return _init

# ë³‘ë ¬ í™˜ê²½ ìƒì„±
env = SubprocVecEnv([make_env(train_videos, i) for i in range(n_envs)])
```

---

### 4. `QUICKSTART.md` âœ…

**ì‚¬ìš©ë²• ì—…ë°ì´íŠ¸**

**BEFORE**:
```bash
python train.py --videos video1.mp4 video2.mp4
```

**AFTER**:
```bash
# Option A: CO3Dv2 (ê¶Œì¥)
python train.py --dataset co3d --num-train-videos 1000 --n-envs 8

# Option B: DTU (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)
python train.py --dataset dtu --num-train-videos 10 --n-envs 4

# Option C: Custom
python train.py --dataset custom --num-train-videos 20 --n-envs 4
```

---

## ì‚¬ìš© ë°©ë²• (Quick Start)

### 1. DTUë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (30ë¶„)

```bash
cd rl_frame_selector/phase1_surrogate

python train.py \
    --dataset dtu \
    --num-train-videos 10 \
    --num-eval-videos 2 \
    --total-timesteps 100000 \
    --n-envs 4 \
    --output-dir ./trained_models/dtu_test \
    --tensorboard-log ./logs/dtu_test
```

### 2. CO3Dv2ë¡œ ë³¸ê²© í•™ìŠµ (1-2ì‹œê°„)

**ì „ì œì¡°ê±´**: CO3Dv2 ë‹¤ìš´ë¡œë“œ í•„ìš”
```bash
# CO3Dv2 ë‹¤ìš´ë¡œë“œ (https://github.com/facebookresearch/co3d)
# /data/co3d/ ì— ì••ì¶• í•´ì œ
```

**í•™ìŠµ ì‹¤í–‰**:
```bash
python train.py \
    --dataset co3d \
    --num-train-videos 1000 \
    --num-eval-videos 100 \
    --total-timesteps 500000 \
    --n-envs 8 \
    --output-dir ./trained_models/co3d_1k \
    --tensorboard-log ./logs/co3d_1k
```

### 3. Zero-shot í…ŒìŠ¤íŠ¸

í•™ìŠµ ì™„ë£Œ í›„ ìƒˆ ë¹„ë””ì˜¤ì— ì¦‰ì‹œ ì ìš©:
```python
from stable_baselines3 import PPO
from env import FrameSelectionEnv

# í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ
model = PPO.load("./trained_models/co3d_1k/final_model.zip")

# ìƒˆ ë¹„ë””ì˜¤ì— ì ìš© (ì¬í•™ìŠµ ë¶ˆí•„ìš”!)
env = FrameSelectionEnv(
    video_path="NEW_UNSEEN_VIDEO.mp4",
    num_source_frames=300,
    target_frames=60
)

obs, _ = env.reset()
for _ in range(300):
    action, _ = model.predict(obs, deterministic=True)
    obs, reward, done, truncated, info = env.step(action)
    if done or truncated:
        break

print(f"Zero-shot ì„±ëŠ¥: Reward = {reward:.4f}")
```

---

## ê¸°ëŒ€ íš¨ê³¼

### BEFORE (Single-Video Training)
```
- í•™ìŠµ: 1ê°œ ë¹„ë””ì˜¤, 100k timesteps, 10ë¶„
- ì ìš©: ê°™ì€ ë¹„ë””ì˜¤ì—ë§Œ ìœ íš¨
- ìƒˆ ë¹„ë””ì˜¤: ì¬í•™ìŠµ í•„ìš” (10ë¶„)
- í™•ì¥ì„±: âŒ
```

### AFTER (Multi-Video Training)
```
- í•™ìŠµ: 1,000ê°œ ë¹„ë””ì˜¤, 500k timesteps, 1-2ì‹œê°„ (1íšŒ)
- ì ìš©: ëª¨ë“  ë¹„ë””ì˜¤ì— zero-shot
- ìƒˆ ë¹„ë””ì˜¤: ì¬í•™ìŠµ ë¶ˆí•„ìš” (0ë¶„)
- í™•ì¥ì„±: âœ… ê³µê°œ ë°ì´í„°ì…‹ ì‚¬ìš©ìœ¼ë¡œ ì¬í˜„ ê°€ëŠ¥
```

### í•™ìˆ ì  ê°€ì¹˜
- í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ (CO3Dv2) ì‚¬ìš© â†’ ì¬í˜„ì„± ë³´ì¥
- Zero-shot generalization ë‹¬ì„±
- ë…¼ë¬¸/í•™íšŒ ì œì¶œ ê°€ëŠ¥ (WACV 2026)

---

## ê²€ì¦ ë°©ë²•

### 1. DTU í…ŒìŠ¤íŠ¸ (10ë¶„)

```bash
cd phase1_surrogate

# DTU 10ê°œ ìŠ¤ìº”ìœ¼ë¡œ í•™ìŠµ
python train.py --dataset dtu --num-train-videos 10 --total-timesteps 50000

# Tensorboard í™•ì¸
tensorboard --logdir ./logs
```

### 2. Zero-shot í‰ê°€

í•™ìŠµ ì™„ë£Œ í›„ ìƒˆ ë¹„ë””ì˜¤ë¡œ í…ŒìŠ¤íŠ¸:
```bash
# í•™ìŠµì— ì‚¬ìš©í•˜ì§€ ì•Šì€ DTU scanìœ¼ë¡œ í…ŒìŠ¤íŠ¸
python evaluate.py \
    --model ./trained_models/dtu_test/final_model.zip \
    --video /data/vggt-gaussian-splatting-research/datasets/DTU/scan37_standard
```

### 3. Baseline ë¹„êµ

- Random: ëœë¤ 60ê°œ ì„ íƒ
- Uniform: ê· ë“± ê°„ê²© ì„ íƒ
- Quality-only: í’ˆì§ˆ ìƒìœ„ 60ê°œ
- **RL Agent (Zero-shot)**: CO3Dv2 í•™ìŠµ í›„ ì ìš©

---

## ë‹¤ìŒ ë‹¨ê³„

1. âœ… **DTU ë¹ ë¥¸ í…ŒìŠ¤íŠ¸** (30ë¶„)
   ```bash
   python train.py --dataset dtu --num-train-videos 10
   ```

2. ğŸ”„ **CO3Dv2 ë‹¤ìš´ë¡œë“œ ë° í•™ìŠµ** (ë°ì´í„° ì¤€ë¹„ í•„ìš”)
   - ë‹¤ìš´ë¡œë“œ: https://github.com/facebookresearch/co3d
   - í•™ìŠµ: 1,000ê°œ ë¹„ë””ì˜¤, 1-2ì‹œê°„

3. ğŸ“Š **Zero-shot ì„±ëŠ¥ í‰ê°€**
   - DTU í…ŒìŠ¤íŠ¸ ì„¸íŠ¸
   - Custom ë¹„ë””ì˜¤
   - ì‹¤ì œ 3DGS íŒŒì´í”„ë¼ì¸ (Phase 2)

4. ğŸ“ **ë³´ê³ ì„œ ì‘ì„±**
   - Baseline ë¹„êµ
   - Zero-shot ì„±ëŠ¥ ë¶„ì„
   - WACV 2026 ë…¼ë¬¸ ì´ˆì•ˆ

---

## ì°¸ê³  ìë£Œ

- CO3Dv2 Dataset: https://github.com/facebookresearch/co3d
- CO3Dv2 Paper: [Reizenstein et al., ICCV 2021]
- RL_PROJECT_PROPOSAL.md: ì „ì²´ ì—°êµ¬ ê³„íš
- QUICKSTART.md: 5ë¶„ ì‹œì‘ ê°€ì´ë“œ

---

âœ… **ë³€ê²½ ì‚¬í•­ ë°˜ì˜ ì™„ë£Œ!**

ì´ì œ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµí•˜ì—¬ zero-shot generalizationì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
