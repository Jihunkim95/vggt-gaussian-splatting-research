#!/bin/bash

# íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë° ê²°ê³¼ ì €ì¥ ìŠ¤í¬ë¦½íŠ¸
# ì‚¬ìš©ë²•: ./run_pipeline.sh <íŒŒì´í”„ë¼ì¸> [ë°ì´í„°ì…‹_ë””ë ‰í† ë¦¬]

# PyTorch CUDA ë©”ëª¨ë¦¬ ë‹¨í¸í™” ë°©ì§€
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

# H100 GPU ì§€ì› (compute capability 9.0)
export TORCH_CUDA_ARCH_LIST="9.0"
export CUDA_HOME=/opt/cuda-12.1
export PATH=/opt/cuda-12.1/bin:$PATH
export TMPDIR=/data/tmp

PIPELINE="$1"
DATA_DIR="${2:-./datasets/DTU/scan1_standard}"  # ê¸°ë³¸ê°’: scan1_standard
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
RESULTS_BASE="./results"

# ë°ì´í„°ì…‹ ê²½ë¡œì—ì„œ ìŠ¤ìº” ì´ë¦„ ì¶”ì¶œ (ì˜ˆ: scan24_standard â†’ scan24)
SCAN_NAME=$(basename "$DATA_DIR" | sed 's/_standard$//')

if [ -z "$PIPELINE" ]; then
    echo "ì‚¬ìš©ë²•: $0 <P1|P1R|P2|P3|P4|P5> [ë°ì´í„°ì…‹_ë””ë ‰í† ë¦¬]"
    echo ""
    echo "íŒŒì´í”„ë¼ì¸ ì„¤ëª…:"
    echo "  P1: Original COLMAP SfM + gsplat (Images only)"
    echo "  P2: VGGT Feed-Forward Only"
    echo "  P3: VGGT + Bundle Adjustment"
    echo "  P4: VGGT â†’ COLMAP â†’ gsplat"
    echo "  P5: Advanced Hybrid Pipeline"
    echo ""
    echo "ì˜ˆì‹œ:"
    echo "  $0 P5                                    # ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©"
    echo "  $0 P5 ./datasets/DTU/scan1_standard      # ëª…ì‹œì  ê²½ë¡œ ì§€ì •"
    echo "  $0 P5 ./datasets/DTU/custom_scene        # ì»¤ìŠ¤í…€ ì”¬ ì‚¬ìš©"
    exit 1
fi

# ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ ê²€ì¦
STANDARD_DIR="$DATA_DIR"
if [ ! -d "$STANDARD_DIR/images" ]; then
    echo "âŒ ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ images í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: $STANDARD_DIR"
    echo "ğŸ”§ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”: ./prepare_standard_dataset.sh '<ì›ë³¸_ì´ë¯¸ì§€_ê²½ë¡œ>'"
    echo ""
    echo "ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹:"
    find ./datasets -type d -name "images" 2>/dev/null | sed 's|/images||' | head -5
    exit 1
fi

# ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„± (ìŠ¤ìº” ì´ë¦„ í¬í•¨)
RESULT_DIR="${RESULTS_BASE}/${PIPELINE}_${SCAN_NAME}_${TIMESTAMP}"
mkdir -p "$RESULT_DIR"

# ì„ì‹œ ì‘ì—… ë””ë ‰í† ë¦¬ ìƒì„± (ì¶©ëŒ ë°©ì§€)
TEMP_WORK_DIR="./temp_work_${PIPELINE}_${TIMESTAMP}"
cp -r "$STANDARD_DIR" "$TEMP_WORK_DIR"
echo "ğŸ”§ ì„ì‹œ ì‘ì—… ë””ë ‰í† ë¦¬: $TEMP_WORK_DIR"

echo "ğŸš€ íŒŒì´í”„ë¼ì¸ $PIPELINE ì‹¤í–‰ ì‹œì‘"
echo "ğŸ“ ê²°ê³¼ ì €ì¥: $RESULT_DIR"
echo "â° ì‹œì‘ ì‹œê°„: $(date)"

# ì‹œì‘ ì‹œê°„ ê¸°ë¡
START_TIME=$(date +%s)

case "$PIPELINE" in
    "P1")
        echo "ğŸ“‹ P1: Original COLMAP SfM + gsplat (Images Only) ì‹¤í–‰"
        echo "ğŸ”§ gsplat í™˜ê²½ í™œì„±í™” ì¤‘..."
        source ./env/gsplat_env/bin/activate

        # gsplat í™˜ê²½ì— í•„ìš”í•œ ì¶”ê°€ íŒ¨í‚¤ì§€ í™•ì¸
        echo "ğŸ“¦ í•„ìš” íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸ ì¤‘..."
        export TMPDIR=/data/tmp
        export TORCH_CUDA_ARCH_LIST="9.0"
        pip install --no-deps imageio tqdm tyro > /dev/null 2>&1 || true

        # ê¸°ì¡´ sparse ì¬êµ¬ì„± ì œê±°í•˜ì—¬ ì´ë¯¸ì§€ë§Œìœ¼ë¡œ ì‹œì‘ (ì§„ì§œ COLMAP SfM)
        if [ -d "$TEMP_WORK_DIR/sparse" ]; then
            echo "ğŸ§¹ ê¸°ì¡´ sparse ì¬êµ¬ì„± ì œê±° (ì´ë¯¸ì§€ë§Œìœ¼ë¡œ ì‹œì‘)"
            rm -rf "$TEMP_WORK_DIR/sparse"
        fi
        python p1_baseline.py \
            --data-dir "$TEMP_WORK_DIR" \
            --output-dir "$RESULT_DIR" \
            --data-factor 1 \
            --max-steps 30000 \
            --eval-steps 30000 \
            --save-steps 7000 15000 30000 \
            --ply-steps 7000 15000 30000 \
            --save-ply \
            --disable-viewer \
            --tb-every 1000
        ;;

    "P2")
        echo "ğŸ“‹ P2: VGGT Feed-Forward Only ì‹¤í–‰"
        source ./env/vggt_env/bin/activate
        PYTHONPATH=./libs/vggt:$PYTHONPATH python demo_colmap.py \
            --scene_dir "$TEMP_WORK_DIR" \
            --conf_thres_value 5.0

        # ê²°ê³¼ ë³µì‚¬
        cp -r "$TEMP_WORK_DIR/sparse" "$RESULT_DIR/"
        ;;

    "P3")
        echo "ğŸ“‹ P3: VGGT + Bundle Adjustment ì‹¤í–‰"
        source ./env/vggt_env/bin/activate
        PYTHONPATH=./libs/vggt:$PYTHONPATH python demo_colmap.py \
            --scene_dir "$TEMP_WORK_DIR" \
            --use_ba \
            --conf_thres_value 5.0 \
            --max_reproj_error 8.0 \
            --max_query_pts 4096

        # ê²°ê³¼ ë³µì‚¬
        cp -r "$TEMP_WORK_DIR/sparse" "$RESULT_DIR/"
        ;;

    "P4")
        echo "ğŸ“‹ P4: VGGT Feed-Forward â†’ gsplat ì‹¤í–‰"

        # Step 1: VGGT Feed-Forward (vggt_env)
        echo "ğŸ”´ Step 1: VGGT Feed-Forward"
        source ./env/vggt_env/bin/activate
        PYTHONPATH=./libs/vggt:$PYTHONPATH python demo_colmap.py \
            --scene_dir "$TEMP_WORK_DIR" \
            --conf_thres_value 5.0

        # Verify VGGT output
        if [ ! -f "$TEMP_WORK_DIR/sparse/points3D.bin" ]; then
            echo "âŒ VGGT feed-forward failed - no sparse reconstruction"
            exit 1
        fi
        echo "âœ… VGGT sparse reconstruction completed"

        # Step 2: gsplat Training (gsplat_env)
        echo "ğŸ”µ Step 2: gsplat Training"
        source ./env/gsplat_env/bin/activate

        # gsplat í™˜ê²½ì— í•„ìš”í•œ ì¶”ê°€ íŒ¨í‚¤ì§€ í™•ì¸
        echo "ğŸ“¦ í•„ìš” íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸ ì¤‘..."
        export TMPDIR=/data/tmp
        export TORCH_CUDA_ARCH_LIST="9.0"
        pip install --no-deps imageio tqdm tyro > /dev/null 2>&1 || true

        python ./libs/gsplat/examples/simple_trainer.py default \
            --data-dir "$TEMP_WORK_DIR" \
            --result-dir "$RESULT_DIR" \
            --data-factor 1 \
            --max-steps 30000 \
            --eval-steps 30000 \
            --save-steps 7000 15000 30000 \
            --ply-steps 7000 15000 30000 \
            --save-ply \
            --disable-viewer \
            --tb-every 1000

        # ê²°ê³¼ ë³µì‚¬ (VGGT sparseë„ í•¨ê»˜)
        cp -r "$TEMP_WORK_DIR/sparse" "$RESULT_DIR/vggt_sparse"
        ;;

    "P5")
        echo "ğŸ“‹ P5: VGGT + Bundle Adjustment â†’ gsplat ì‹¤í–‰"

        # Step 1: VGGT + Bundle Adjustment (vggt_env)
        echo "ğŸŸ¢ Step 1: VGGT + Bundle Adjustment"
        source ./env/vggt_env/bin/activate
        PYTHONPATH=./libs/vggt:$PYTHONPATH python demo_colmap.py \
            --scene_dir "$TEMP_WORK_DIR" \
            --use_ba \
            --conf_thres_value 5.0 \
            --max_reproj_error 8.0 \
            --max_query_pts 4096

        # Verify VGGT+BA output
        if [ ! -f "$TEMP_WORK_DIR/sparse/points3D.bin" ]; then
            echo "âŒ VGGT + Bundle Adjustment failed - no sparse reconstruction"
            exit 1
        fi
        echo "âœ… VGGT + Bundle Adjustment reconstruction completed"

        # Step 2: gsplat Training (gsplat_env)
        echo "ğŸ”µ Step 2: gsplat Training"
        source ./env/gsplat_env/bin/activate

        # gsplat í™˜ê²½ì— í•„ìš”í•œ ì¶”ê°€ íŒ¨í‚¤ì§€ í™•ì¸
        echo "ğŸ“¦ í•„ìš” íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸ ì¤‘..."
        export TMPDIR=/data/tmp
        export TORCH_CUDA_ARCH_LIST="9.0"
        pip install --no-deps imageio tqdm tyro > /dev/null 2>&1 || true

        python ./libs/gsplat/examples/simple_trainer.py default \
            --data-dir "$TEMP_WORK_DIR" \
            --result-dir "$RESULT_DIR" \
            --data-factor 1 \
            --max-steps 30000 \
            --eval-steps 30000 \
            --save-steps 7000 15000 30000 \
            --ply-steps 7000 15000 30000 \
            --save-ply \
            --disable-viewer \
            --tb-every 1000

        # ê²°ê³¼ ë³µì‚¬ (VGGT+BA sparseë„ í•¨ê»˜)
        cp -r "$TEMP_WORK_DIR/sparse" "$RESULT_DIR/vggt_ba_sparse"
        ;;

    *)
        echo "âŒ ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì´í”„ë¼ì¸: $PIPELINE"
        exit 1
        ;;
esac

# ì¢…ë£Œ ì‹œê°„ ê¸°ë¡
END_TIME=$(date +%s)
DURATION=$((END_TIME - START_TIME))

# ê²°ê³¼ ë¶„ì„ ë° ì €ì¥
echo "ğŸ“Š ê²°ê³¼ ë¶„ì„ ì¤‘..."

# GPU ì •ë³´ ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°
GPU_NAME=$(nvidia-smi --query-gpu=name --format=csv,noheader | head -1 || echo "Unknown GPU")

# ë©”íƒ€ë°ì´í„° ìƒì„±
cat > "$RESULT_DIR/metadata.json" << EOF
{
    "pipeline": "$PIPELINE",
    "timestamp": "$TIMESTAMP",
    "start_time": "$(date -d @$START_TIME)",
    "end_time": "$(date -d @$END_TIME)",
    "duration_seconds": $DURATION,
    "standard_dataset": "$STANDARD_DIR",
    "temp_work_dir": "$TEMP_WORK_DIR",
    "isolation": "true",
    "git_commit": "$(git rev-parse HEAD)",
    "system": {
        "hostname": "$(hostname)",
        "gpu": "$GPU_NAME",
        "python_env": "vggt_env"
    }
}
EOF

# ê²°ê³¼ ë¶„ì„ (pycolmapì´ í•„ìš”í•œ ê²½ìš°)
# P2/P3 â†’ sparse, P4 â†’ vggt_sparse, P5 â†’ vggt_ba_sparse ìˆœì„œë¡œ í™•ì¸
SPARSE_DIR=""
if [ -f "$RESULT_DIR/sparse/points3D.bin" ]; then
    SPARSE_DIR="$RESULT_DIR/sparse"
elif [ -f "$RESULT_DIR/vggt_ba_sparse/points3D.bin" ]; then
    SPARSE_DIR="$RESULT_DIR/vggt_ba_sparse"
elif [ -f "$RESULT_DIR/vggt_sparse/points3D.bin" ]; then
    SPARSE_DIR="$RESULT_DIR/vggt_sparse"
fi

if [ -n "$SPARSE_DIR" ]; then
    source ./env/vggt_env/bin/activate
    python -c "
import pycolmap
import json
import os

sparse_dir = '$SPARSE_DIR'
result_dir = '$RESULT_DIR'
reconstruction = pycolmap.Reconstruction(sparse_dir)

# PLY íŒŒì¼ ê²½ë¡œ ì°¾ê¸°
ply_path = os.path.join(sparse_dir, 'points.ply')
ply_size_mb = round(os.path.getsize(ply_path) / (1024*1024), 2) if os.path.exists(ply_path) else 0

results = {
    'images_count': len(reconstruction.images),
    'points3D_count': len(reconstruction.points3D),
    'cameras_count': len(reconstruction.cameras),
    'ply_file_size_mb': ply_size_mb,
    'sparse_reconstruction_dir': os.path.basename(sparse_dir)
}

with open(os.path.join(result_dir, 'analysis.json'), 'w') as f:
    json.dump(results, f, indent=2)

print(f'âœ… {results[\"points3D_count\"]:,} 3D points generated')
print(f'ğŸ“ PLY file: {results[\"ply_file_size_mb\"]} MB')
print(f'ğŸ“‚ Sparse dir: {results[\"sparse_reconstruction_dir\"]}')
"
fi

# P1 ê²°ê³¼ì—ì„œ íƒ€ì´ë° ì •ë³´ í†µí•©
if [ "$PIPELINE" = "P1" ] && [ -f "$RESULT_DIR/timing_results.json" ]; then
    echo "ğŸ“Š P1 íƒ€ì´ë° ê²°ê³¼ í†µí•© ì¤‘..."
    python -c "
import json
import os

result_dir = '$RESULT_DIR'
timing_file = os.path.join(result_dir, 'timing_results.json')
analysis_file = os.path.join(result_dir, 'analysis.json')

# íƒ€ì´ë° ë°ì´í„° ë¡œë“œ
with open(timing_file, 'r') as f:
    timing_data = json.load(f)

# ê¸°ì¡´ ë¶„ì„ ë°ì´í„°ê°€ ìˆìœ¼ë©´ í†µí•©
if os.path.exists(analysis_file):
    with open(analysis_file, 'r') as f:
        analysis_data = json.load(f)
    analysis_data.update(timing_data)
else:
    analysis_data = timing_data

# í†µí•©ëœ ê²°ê³¼ ì €ì¥
with open(analysis_file, 'w') as f:
    json.dump(analysis_data, f, indent=2)

print(f'âœ… íƒ€ì´ë° ì •ë³´ í†µí•© ì™„ë£Œ')
print(f'â±ï¸ ì´ íŒŒì´í”„ë¼ì¸ ì‹œê°„: {timing_data[\"pipeline_total_seconds\"]}ì´ˆ')
print(f'â±ï¸ í›ˆë ¨ ì‹œê°„: {timing_data[\"training_seconds\"]}ì´ˆ')
"
fi

# ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬
rm -rf "$TEMP_WORK_DIR"
echo "ğŸ§¹ ì„ì‹œ ì‘ì—… ë””ë ‰í† ë¦¬ ì •ë¦¬ ì™„ë£Œ"

echo "âœ… $PIPELINE íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!"
echo "â±ï¸ ì´ ì†Œìš”ì‹œê°„: ${DURATION}ì´ˆ"
echo "ğŸ“ ê²°ê³¼ ìœ„ì¹˜: $RESULT_DIR"
echo "ğŸ“Š ë¶„ì„ íŒŒì¼: $RESULT_DIR/metadata.json, $RESULT_DIR/analysis.json"