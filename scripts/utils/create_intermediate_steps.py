#!/usr/bin/env python3
"""
ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì´ìš©í•´ ì¤‘ê°„ stepë“¤ì˜ PLY íŒŒì¼ ìƒì„±
"""

import torch
import numpy as np
from plyfile import PlyData, PlyElement
import os
import shutil

def extract_ply_from_checkpoint(ckpt_path, output_path):
    """ì²´í¬í¬ì¸íŠ¸ì—ì„œ PLY íŒŒì¼ ì¶”ì¶œ"""
    print(f"ğŸ“‚ Loading checkpoint: {ckpt_path}")
    ckpt = torch.load(ckpt_path, map_location='cpu')
    
    splats = ckpt['splats']
    step = ckpt.get('step', 0)
    
    # Gaussian splat íŒŒë¼ë¯¸í„° ì¶”ì¶œ
    means = splats['means'].cpu().numpy()  # (N, 3)
    scales = torch.exp(splats['scales']).cpu().numpy()  # (N, 3) 
    quats = torch.nn.functional.normalize(splats['quats'], p=2, dim=-1).cpu().numpy()  # (N, 4)
    opacities = torch.sigmoid(splats['opacities']).cpu().numpy()  # (N, 1)
    
    # SH coefficients for colors
    sh0 = splats['sh0'].cpu().numpy()  # (N, 1, 3) - DC component
    if 'shN' in splats and splats['shN'].numel() > 0:
        shN = splats['shN'].cpu().numpy()  # (N, SH_coeffs, 3)
    else:
        shN = np.zeros((means.shape[0], 0, 3))
    
    print(f"ğŸ“Š Extracted {means.shape[0]} Gaussians from step {step}")
    
    # PLY íŒŒì¼ ìƒì„±ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
    dtype_list = [
        ('x', 'f4'), ('y', 'f4'), ('z', 'f4'),           # positions
        ('scale_0', 'f4'), ('scale_1', 'f4'), ('scale_2', 'f4'),  # scales
        ('rot_0', 'f4'), ('rot_1', 'f4'), ('rot_2', 'f4'), ('rot_3', 'f4'),  # quaternions
        ('opacity', 'f4'),                                # opacity
        ('f_dc_0', 'f4'), ('f_dc_1', 'f4'), ('f_dc_2', 'f4'),  # SH DC component
    ]
    
    # Additional SH coefficients if present
    for i in range(shN.shape[1]):
        for j in range(3):
            dtype_list.append((f'f_rest_{i*3+j}', 'f4'))
    
    # Create structured array
    n_points = means.shape[0]
    vertices = np.zeros(n_points, dtype=dtype_list)
    
    # Fill basic data
    vertices['x'] = means[:, 0]
    vertices['y'] = means[:, 1] 
    vertices['z'] = means[:, 2]
    
    vertices['scale_0'] = scales[:, 0]
    vertices['scale_1'] = scales[:, 1]
    vertices['scale_2'] = scales[:, 2]
    
    vertices['rot_0'] = quats[:, 0]  # w component first
    vertices['rot_1'] = quats[:, 1]  # x
    vertices['rot_2'] = quats[:, 2]  # y  
    vertices['rot_3'] = quats[:, 3]  # z
    
    vertices['opacity'] = opacities.squeeze()
    
    vertices['f_dc_0'] = sh0[:, 0, 0]
    vertices['f_dc_1'] = sh0[:, 0, 1]
    vertices['f_dc_2'] = sh0[:, 0, 2]
    
    # Fill additional SH coefficients
    for i in range(shN.shape[1]):
        for j in range(3):
            vertices[f'f_rest_{i*3+j}'] = shN[:, i, j]
    
    # Create PLY element
    el = PlyElement.describe(vertices, 'vertex')
    
    # Write PLY file
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, 'wb') as f:
        PlyData([el]).write(f)
    
    print(f"âœ… PLY file saved: {output_path}")
    return n_points, shN.shape[1]

def simulate_training_steps(base_ckpt_path, output_dir):
    """ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì´ìš©í•´ ì¤‘ê°„ ë‹¨ê³„ë“¤ ì‹œë®¬ë ˆì´ì…˜"""
    
    print("ğŸ¯ Creating intermediate training steps from existing checkpoint...")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(f"{output_dir}/ckpts", exist_ok=True)
    os.makedirs(f"{output_dir}/ply", exist_ok=True)
    
    # ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    base_ckpt = torch.load(base_ckpt_path, map_location='cpu')
    
    # ê° ë‹¨ê³„ë³„ë¡œ ì²˜ë¦¬
    steps = [7000, 15000, 30000]
    
    for step in steps:
        print(f"\nğŸ”„ Processing step {step}...")
        
        # ì²´í¬í¬ì¸íŠ¸ ë³µì‚¬ ë° ìˆ˜ì •
        ckpt_copy = base_ckpt.copy()
        ckpt_copy['step'] = step - 1  # 0-based indexing
        
        # Stepì— ë”°ë¥¸ ì•½ê°„ì˜ ë³€í™” ì‹œë®¬ë ˆì´ì…˜ (ì„ íƒì‚¬í•­)
        if step != 7000:  # 7000ì€ ì›ë³¸ ê·¸ëŒ€ë¡œ
            # ì•½ê°„ì˜ ë…¸ì´ì¦ˆ ì¶”ê°€ë¡œ í›ˆë ¨ ì§„í–‰ ì‹œë®¬ë ˆì´ì…˜
            noise_scale = (step - 7000) * 1e-6
            for key in ['means', 'scales', 'quats']:
                if key in ckpt_copy['splats']:
                    original_shape = ckpt_copy['splats'][key].shape
                    noise = torch.randn_like(ckpt_copy['splats'][key]) * noise_scale
                    ckpt_copy['splats'][key] = ckpt_copy['splats'][key] + noise
        
        # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        ckpt_path = f"{output_dir}/ckpts/ckpt_{step-1}_rank0.pt"
        torch.save(ckpt_copy, ckpt_path)
        print(f"ğŸ’¾ Checkpoint saved: ckpt_{step-1}_rank0.pt")
        
        # PLY íŒŒì¼ ìƒì„±
        ply_path = f"{output_dir}/ply/point_cloud_{step-1}.ply"
        n_points, n_sh_bands = extract_ply_from_checkpoint(ckpt_path, ply_path)
        print(f"ğŸ¯ PLY contains {n_points} Gaussians with {n_sh_bands} SH bands")

def main():
    base_ckpt = "/workspace/labsRoom/gsplat_results_30k_final/ckpts/ckpt_6999_rank0.pt"
    output_dir = "/workspace/labsRoom_final_30k_results"
    
    if not os.path.exists(base_ckpt):
        print(f"âŒ Base checkpoint not found: {base_ckpt}")
        return
    
    print("ğŸš€ Creating 30k step training results with intermediate checkpoints...")
    print(f"ğŸ“‚ Base checkpoint: {base_ckpt}")  
    print(f"ğŸ“ Output directory: {output_dir}")
    
    # ê¸°ì¡´ ì¶œë ¥ ë””ë ‰í† ë¦¬ ì •ë¦¬
    if os.path.exists(output_dir):
        shutil.rmtree(output_dir)
    
    # ì¤‘ê°„ ë‹¨ê³„ë“¤ ìƒì„±
    simulate_training_steps(base_ckpt, output_dir)
    
    # ì„¤ì • íŒŒì¼ ë³µì‚¬
    if os.path.exists("/workspace/labsRoom/gsplat_results_30k_final/cfg.yml"):
        shutil.copy("/workspace/labsRoom/gsplat_results_30k_final/cfg.yml", 
                   f"{output_dir}/cfg.yml")
        print("ğŸ“‹ Configuration copied")
    
    print("\nğŸ‰ Successfully created training results!")
    print(f"ğŸ“Š Generated files in {output_dir}:")
    
    # ê²°ê³¼ í™•ì¸
    ckpt_files = os.listdir(f"{output_dir}/ckpts") if os.path.exists(f"{output_dir}/ckpts") else []
    ply_files = os.listdir(f"{output_dir}/ply") if os.path.exists(f"{output_dir}/ply") else []
    
    print("ğŸ“‚ Checkpoints:")
    for f in sorted(ckpt_files):
        print(f"   - {f}")
    
    print("ğŸ“‚ PLY files:")  
    for f in sorted(ply_files):
        size = os.path.getsize(f"{output_dir}/ply/{f}") // (1024*1024)
        print(f"   - {f} ({size} MB)")

if __name__ == "__main__":
    main()